{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test word2vec embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we create and train different Word2vec models. In particular we tried different combinations of the hyperparameters, in particular for the values of the context window and vector size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import fasttext\n",
    "from datautils import documents_vector\n",
    "import datautils\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import Word2Vec\n",
    "from datautils import documents_vector\n",
    "from datautils import documents_vector_pre\n",
    "PATH = './Dataset/power-gb-train.tsv'\n",
    "RES_DIR = './Results/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below we look for the best comination of the hyperparameteres for the logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def file_logic(X_train,X_val,y_train,y_val,w,s):\n",
    "    #definition of the possible hyperparameters of the logistic regression\n",
    "    hyperparameters1 = {\n",
    "            \"penalty\": [\"l2\"],\n",
    "            \"C\": [0.1, 1.0, 10.0, 100.0, 1000.0,1500],\n",
    "            \"solver\": [\"lbfgs\"],\n",
    "            \"max_iter\": [100, 200, 500,700],\n",
    "        }\n",
    "\n",
    "    param_grid1 = list(ParameterGrid(hyperparameters1))\n",
    "\n",
    "    results_df = pd.DataFrame(\n",
    "        columns=[\"penalty\", \"C\", \"solver\", \"max_iter\", \"F1 Score\",\"Recall\",\"Precision\",\"Vector_size\",\"Window\"]\n",
    "    )\n",
    "\n",
    "    for par1 in param_grid1:\n",
    "                \n",
    "            model = LogisticRegression(**par1)\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            # Compute F1 score on validation set\n",
    "            y_val_pred = model.predict(X_val)\n",
    "            f1_macro = f1_score(y_val, y_val_pred, average=\"macro\")\n",
    "            recall= recall_score(y_val,y_val_pred)\n",
    "            precision=precision_score(y_val,y_val_pred)\n",
    "\n",
    "            print(f\"Parameters: {par1}\")\n",
    "            print(f\"\\tF1 score: {f1_macro}\")\n",
    "            results_df = pd.concat(\n",
    "                [\n",
    "                    results_df,\n",
    "                    pd.DataFrame(\n",
    "                        {\n",
    "                            \"penalty\": par1[\"penalty\"],\n",
    "                            \"C\": par1[\"C\"],\n",
    "                            \"solver\": par1[\"solver\"],\n",
    "                            \"max_iter\": par1[\"max_iter\"],\n",
    "                            \"F1 Score\": f1_macro,\n",
    "                            'Recall':recall,\n",
    "                            'Precision':precision,\n",
    "                            'Vector_size': s,\n",
    "                            'Window': w\n",
    "                            },\n",
    "                        index=[0],\n",
    "                        ),\n",
    "                    ],\n",
    "                    ignore_index=True,\n",
    "                )\n",
    "\n",
    "    results_df.to_csv(RES_DIR+f\"results-Logistic-w2v-batch1-w{w}-s{s}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below we apply a grid search over the values of the context window and vector size of the word2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "#definition of the possible hyperparameters for the context window and vector size\n",
    "hyperparameters2 = {\n",
    "            \"vec\": [150,300,600],\n",
    "            \"window\": [10,20,30,40,50],\n",
    "        }\n",
    "\n",
    "param_grid2 = list(ParameterGrid(hyperparameters2))\n",
    "\n",
    "\n",
    "for par in param_grid2:\n",
    "\n",
    "    X_train, y_train, X_val, y_val, _, _ = datautils.split_holdout_dataset(PATH)\n",
    "\n",
    "    tr_fold = list(map(simple_preprocess, X_train))\n",
    "    val_fold = list(map(simple_preprocess, X_val))\n",
    "\n",
    "    modelw2v = Word2Vec(\n",
    "    tr_fold,\n",
    "    vector_size=par[\"vec\"],\n",
    "    window=par[\"window\"],\n",
    "    min_count=2,\n",
    "    workers=10,\n",
    ")\n",
    "\n",
    "    X_train = documents_vector(tr_fold, modelw2v)\n",
    "    X_val = documents_vector(val_fold, modelw2v)\n",
    "    file_logic(X_train,X_val,y_train,y_val,par[\"window\"],par[\"vec\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below we create and train our word2vec model. In this cell the values of the context window and vector size are already the best of the one that we compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the dataset into training and validation and test set\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = datautils.split_holdout_dataset(PATH)\n",
    "\n",
    "tr_fold = list(map(simple_preprocess, X_train))\n",
    "val_fold = list(map(simple_preprocess, X_val))\n",
    "test_fold = list(map(simple_preprocess, X_test))\n",
    "\n",
    "# w2v model training the best combination of the hyperparameters\n",
    "modelw2v = Word2Vec(\n",
    "    tr_fold,\n",
    "    vector_size=2000,\n",
    "    window=1000,\n",
    "    min_count=2,\n",
    "    workers=10,\n",
    ")\n",
    "\n",
    "# Save word vectors\n",
    "word_vectors = modelw2v.wv\n",
    "word_vectors.save(f\"./Embeddings/w2v-w1000-v2000-skip.kv\")\n",
    "\n",
    "# Pooling\n",
    "X_train = documents_vector(tr_fold, modelw2v)\n",
    "X_val = documents_vector(val_fold, modelw2v)\n",
    "X_test = documents_vector(test_fold, modelw2v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this cell we download a test file for the word analogy in order to evaluate our Word2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "#this is the url of test file\n",
    "url = \"https://raw.githubusercontent.com/nicholas-leonard/word2vec/master/questions-words.txt\"\n",
    "test_file = 'resources/questions-words.txt'\n",
    "questions = requests.get(url).content.decode()\n",
    "with open(test_file,mode='w',encoding='utf-8') as outputfile:\n",
    "    outputfile.write(questions)\n",
    "print(questions[:1000])\n",
    "\n",
    "#we compute the word analogy without dummy4unknown\n",
    "w2v_large_analogy = modelw2v.evaluate_word_analogies(test_file)\n",
    "#we compute the word analogy with dummy4unknown\n",
    "w2v_large_analogy_dummy = modelw2v.evaluate_word_analogies(test_file,dummy4unknown=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we just want to see our score\n",
    "w2v_large_analogy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we just want to see our score\n",
    "w2v_large_analogy_dummy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In  the cell below we took the values of the best hyperparameters  for the logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we create and train the logistic regression withe the best hyperparameters of the logistic regression\n",
    "model = LogisticRegression(penalty='l2',C=10.0,solver='lbfgs',max_iter=500)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Compute F1 score,Recall and Precision on the test set\n",
    "y_test_pred = model.predict(X_test)\n",
    "f1_macro = f1_score(y_test, y_test_pred, average=\"macro\")\n",
    "recall= recall_score(y_test, y_test_pred)\n",
    "precision=precision_score(y_test, y_test_pred)\n",
    "\n",
    "\n",
    "#print of three score that we compute\n",
    "print(f\"\\tF1 score: {f1_macro}\")\n",
    "print(f\"\\tRecall {recall}\")\n",
    "print(f\"\\tPrecision: {precision}\")\n",
    "\n",
    "#we create the dataframe to save the results\n",
    "results_df = pd.DataFrame(\n",
    "        columns=[\"penalty\", \"C\", \"solver\", \"max_iter\", \"F1 Score\",\"Recall\",\"Precision\",\"Vector_size\",\"Window\"]\n",
    "    )\n",
    "results_df = pd.concat(\n",
    "                [\n",
    "                    results_df,\n",
    "                    pd.DataFrame(\n",
    "                        {\n",
    "                            \"penalty\": 'l2',\n",
    "                            \"C\": 10,\n",
    "                            \"solver\": 'lbfgs',\n",
    "                            \"max_iter\": 500,\n",
    "                            \"F1 Score\": f1_macro,\n",
    "                            'Recall':recall,\n",
    "                            'Precision':precision,\n",
    "                            'Vector_size': 2000,\n",
    "                            'Window': 1000\n",
    "                            },\n",
    "                        index=[0],\n",
    "                        ),\n",
    "                    ],\n",
    "                    ignore_index=True,\n",
    "                )\n",
    "\n",
    "results_df.to_csv(RES_DIR+f\"results-Logistic-w2v-test-w1000-s2000.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
