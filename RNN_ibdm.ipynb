{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test RNN on IBDM as benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-04-20 17:18:38--  https://github.com/rasbt/python-machine-learning-book-3rd-edition/raw/master/ch08/movie_data.csv.gz\n",
      "Resolving github.com (github.com)... 140.82.121.3\n",
      "Connecting to github.com (github.com)|140.82.121.3|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/rasbt/python-machine-learning-book-3rd-edition/master/ch08/movie_data.csv.gz [following]\n",
      "--2024-04-20 17:18:39--  https://raw.githubusercontent.com/rasbt/python-machine-learning-book-3rd-edition/master/ch08/movie_data.csv.gz\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 26521894 (25M) [application/octet-stream]\n",
      "Saving to: ‘movie_data.csv.gz’\n",
      "\n",
      "movie_data.csv.gz   100%[===================>]  25.29M  4.55MB/s    in 5.6s    \n",
      "\n",
      "2024-04-20 17:18:45 (4.53 MB/s) - ‘movie_data.csv.gz’ saved [26521894/26521894]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/rasbt/python-machine-learning-book-3rd-edition/raw/master/ch08/movie_data.csv.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gunzip -f movie_data.csv.gz "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In 1974, the teenager Martha Moxley (Maggie Gr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OK... so... I really like Kris Kristofferson a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>***SPOILER*** Do not read this, if you think a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hi for all the people who have seen this wonde...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I recently bought the DVD, forgetting just how...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  In 1974, the teenager Martha Moxley (Maggie Gr...          1\n",
       "1  OK... so... I really like Kris Kristofferson a...          0\n",
       "2  ***SPOILER*** Do not read this, if you think a...          0\n",
       "3  hi for all the people who have seen this wonde...          1\n",
       "4  I recently bought the DVD, forgetting just how...          0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('movie_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext\n",
    "from sklearn.model_selection import train_test_split\n",
    "import datautils\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 123\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "VOCABULARY_SIZE = 20000\n",
    "LEARNING_RATE = 0.005\n",
    "BATCH_SIZE = 2048\n",
    "NUM_EPOCHS = 30\n",
    "DEVICE = datautils.get_device()\n",
    "\n",
    "EMBEDDING_DIM = 128\n",
    "HIDDEN_DIM = 256\n",
    "NUM_CLASSES = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_tokenizer = torchtext.data.utils.get_tokenizer(\n",
    "    'spacy',\n",
    "    language='en_core_web_sm',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: 40000, X_test: 10000\n",
      "X_train: 34000, X_val: 6000\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['review'], df['sentiment'], test_size=0.2, random_state=RANDOM_SEED)\n",
    "print(f'X_train: {len(X_train)}, X_test: {len(X_test)}')\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.15, random_state=RANDOM_SEED)\n",
    "print(f'X_train: {len(X_train)}, X_val: {len(X_val)}')\n",
    "\n",
    "X_train.reset_index(drop=True,inplace=True)\n",
    "X_val.reset_index(drop=True,inplace=True)\n",
    "X_test.reset_index(drop=True,inplace=True)\n",
    "y_train.reset_index(drop=True,inplace=True)\n",
    "y_val.reset_index(drop=True,inplace=True)\n",
    "y_test.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19331"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build vocabulary on training set\n",
    "curr_vocab = datautils.build_vocab(X_train, en_tokenizer,min_freq=18)\n",
    "curr_vocab.set_default_index(curr_vocab[\"<unk>\"])\n",
    "len(curr_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#process datasets\n",
    "X_train = datautils.data_process(X_train, curr_vocab, en_tokenizer)\n",
    "X_val = datautils.data_process(X_val, curr_vocab, en_tokenizer)\n",
    "X_test = datautils.data_process(X_test, curr_vocab, en_tokenizer)\n",
    "\n",
    "#create datasets for dataloader\n",
    "train_dataset = datautils.TextDataset(X_train, y_train,curr_vocab)\n",
    "val_dataset = datautils.TextDataset(X_val, y_val, curr_vocab)\n",
    "test_dataset = datautils.TextDataset(X_test, y_test, curr_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare dataloader\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    collate_fn=train_dataset.generate_batch,\n",
    ")\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    collate_fn=val_dataset.generate_batch,\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    collate_fn=test_dataset.generate_batch,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "Text matrix size: torch.Size([2048, 1827])\n",
      "Target vector size: torch.Size([2048, 1])\n",
      "Val\n",
      "Text matrix size: torch.Size([2048, 2637])\n",
      "Target vector size: torch.Size([2048, 1])\n",
      "Test\n",
      "Text matrix size: torch.Size([2048, 1411])\n",
      "Target vector size: torch.Size([2048, 1])\n"
     ]
    }
   ],
   "source": [
    "print('Train')\n",
    "for batch in train_loader:\n",
    "    print(f'Text matrix size: {batch[0].size()}')\n",
    "    print(f'Target vector size: {batch[1].size()}')\n",
    "    break\n",
    "print('Val')\n",
    "for batch in val_loader:\n",
    "    print(f'Text matrix size: {batch[0].size()}')\n",
    "    print(f'Target vector size: {batch[1].size()}')\n",
    "    break\n",
    "print('Test')\n",
    "for batch in test_loader:\n",
    "    print(f'Text matrix size: {batch[0].size()}')\n",
    "    print(f'Target vector size: {batch[1].size()}')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import RNNutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(RANDOM_SEED)\n",
    "model = RNNutils.RNN(len(curr_vocab), EMBEDDING_DIM, HIDDEN_DIM)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "criterion = torch.nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Evaluating...\n",
      "| Epoch: 01 | Train Loss: 0.726 | Val Loss: 0.681 | Precision: 0.57 | Recall: 0.55 | F1 Score: 0.51 |\n",
      "Epoch: 2\n",
      "Evaluating...\n",
      "| Epoch: 02 | Train Loss: 0.670 | Val Loss: 0.668 | Precision: 0.60 | Recall: 0.59 | F1 Score: 0.57 |\n",
      "Epoch: 3\n",
      "Evaluating...\n",
      "| Epoch: 03 | Train Loss: 0.665 | Val Loss: 0.666 | Precision: 0.58 | Recall: 0.58 | F1 Score: 0.58 |\n",
      "Epoch: 4\n",
      "Evaluating...\n",
      "| Epoch: 04 | Train Loss: 0.672 | Val Loss: 0.678 | Precision: 0.57 | Recall: 0.57 | F1 Score: 0.57 |\n",
      "Epoch: 5\n",
      "Evaluating...\n",
      "| Epoch: 05 | Train Loss: 0.682 | Val Loss: 0.684 | Precision: 0.53 | Recall: 0.53 | F1 Score: 0.53 |\n",
      "Epoch: 6\n",
      "Evaluating...\n",
      "| Epoch: 06 | Train Loss: 0.668 | Val Loss: 0.661 | Precision: 0.60 | Recall: 0.60 | F1 Score: 0.60 |\n",
      "Epoch: 7\n",
      "Evaluating...\n",
      "| Epoch: 07 | Train Loss: 0.626 | Val Loss: 0.654 | Precision: 0.62 | Recall: 0.62 | F1 Score: 0.62 |\n",
      "Epoch: 8\n",
      "Evaluating...\n",
      "| Epoch: 08 | Train Loss: 0.623 | Val Loss: 0.655 | Precision: 0.60 | Recall: 0.60 | F1 Score: 0.60 |\n",
      "Epoch: 9\n",
      "Evaluating...\n",
      "| Epoch: 09 | Train Loss: 0.632 | Val Loss: 0.649 | Precision: 0.63 | Recall: 0.63 | F1 Score: 0.63 |\n",
      "Epoch: 10\n",
      "Evaluating...\n",
      "| Epoch: 10 | Train Loss: 0.567 | Val Loss: 0.681 | Precision: 0.63 | Recall: 0.62 | F1 Score: 0.62 |\n",
      "Epoch: 11\n",
      "Evaluating...\n",
      "| Epoch: 11 | Train Loss: 0.534 | Val Loss: 0.620 | Precision: 0.68 | Recall: 0.68 | F1 Score: 0.68 |\n",
      "Epoch: 12\n",
      "Evaluating...\n",
      "| Epoch: 12 | Train Loss: 0.510 | Val Loss: 0.624 | Precision: 0.68 | Recall: 0.68 | F1 Score: 0.68 |\n",
      "Epoch: 13\n",
      "Evaluating...\n",
      "| Epoch: 13 | Train Loss: 0.513 | Val Loss: 0.620 | Precision: 0.68 | Recall: 0.68 | F1 Score: 0.68 |\n",
      "Epoch: 14\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    print(f'Epoch: {epoch}')\n",
    "    train_loss = RNNutils.train_rnn(model, train_loader, optimizer, criterion,1)\n",
    "    print(f'Evaluating...')\n",
    "    val_loss , precision , recall, fscore = RNNutils.evaluate(model,val_loader,criterion)\n",
    "\n",
    "    print(f'| Epoch: {epoch:02} | Train Loss: {train_loss:.3f} | Val Loss: {val_loss:.3f} | Precision: {precision:.2f} | Recall: {recall:.2f} | F1 Score: {fscore:.2f} |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HLT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
