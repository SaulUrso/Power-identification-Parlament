{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook regarding measurements with RNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datautils\n",
    "import torch\n",
    "import torchtext\n",
    "from torch.utils.data import DataLoader\n",
    "import pickle\n",
    "import torch.nn as nn\n",
    "import RNNutils\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = \"./Dataset/power-gb-train.tsv\"\n",
    "DATA_DIR = \"./Dataset/\"\n",
    "RES_DIR = \"./Results/\"\n",
    "EMBED_DIR = \"./Embeddings/\"\n",
    "CHECK_DIR = \"./Checkpoints/\"\n",
    "DEVICE = datautils.get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.downloader import load\n",
    "\n",
    "EMBEDDING=\"word2vec-ruscorpora-300\"\n",
    "#download the embedding\n",
    "pretrained_embeddings=load(EMBEDDING)\n",
    "vector_embeddings=None\n",
    "with open(f\"{EMBED_DIR}vocab.pkl\", \"rb\") as f:\n",
    "    curr_vocab = pickle.load(f)\n",
    "    # Create a matrix to store the vectors\n",
    "    vector_embeddings = torch.zeros(len(curr_vocab), pretrained_embeddings.vector_size)\n",
    "\n",
    "    # Set the vectors for our vocabulary words\n",
    "    for i, word in enumerate(curr_vocab.get_itos()):\n",
    "        if word in pretrained_embeddings:\n",
    "            vector_embeddings[i] = torch.tensor(pretrained_embeddings[word]) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load the dataset (with hold-out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72276 2 min_freq\n",
      "46491 3 min_freq\n",
      "37987 4 min_freq\n",
      "33080 5 min_freq\n",
      "29729 6 min_freq\n",
      "27245 7 min_freq\n",
      "25353 8 min_freq\n",
      "23816 9 min_freq\n",
      "22555 10 min_freq\n",
      "21529 11 min_freq\n",
      "20552 12 min_freq\n",
      "19712 13 min_freq\n",
      "18970 14 min_freq\n",
      "18299 15 min_freq\n",
      "17669 16 min_freq\n",
      "17070 17 min_freq\n",
      "16575 18 min_freq\n",
      "16108 19 min_freq\n",
      "15623 20 min_freq\n",
      "15203 21 min_freq\n",
      "14864 22 min_freq\n",
      "14495 23 min_freq\n",
      "14173 24 min_freq\n",
      "13883 25 min_freq\n",
      "13564 26 min_freq\n",
      "13267 27 min_freq\n",
      "12996 28 min_freq\n",
      "12756 29 min_freq\n",
      "12553 30 min_freq\n",
      "12356 31 min_freq\n",
      "12150 32 min_freq\n",
      "11959 33 min_freq\n",
      "11747 34 min_freq\n",
      "11550 35 min_freq\n",
      "11374 36 min_freq\n",
      "11174 37 min_freq\n",
      "10984 38 min_freq\n",
      "10830 39 min_freq\n",
      "10679 40 min_freq\n",
      "10514 41 min_freq\n",
      "10381 42 min_freq\n",
      "10228 43 min_freq\n",
      "10092 44 min_freq\n",
      "9944 45 min_freq\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = datautils.split_holdout_dataset(DATASET)\n",
    "\n",
    "# get tokenizer\n",
    "tokenizer = torchtext.data.utils.get_tokenizer(\n",
    "    \"spacy\", language=\"en_core_web_sm\"\n",
    ")\n",
    "\n",
    "# build vocabulary\n",
    "min_freq = 1\n",
    "curr_vocab = None\n",
    "while curr_vocab is None or len(curr_vocab) > 10000:\n",
    "    curr_vocab = datautils.build_vocab(X_train, tokenizer, min_freq=min_freq)\n",
    "    curr_vocab.set_default_index(curr_vocab[\"<unk>\"])\n",
    "    min_freq += 1\n",
    "    print(len(curr_vocab),f\"{min_freq} min_freq\")\n",
    "\n",
    "# process datasets\n",
    "X_train = datautils.data_process(X_train, curr_vocab, tokenizer)\n",
    "X_val = datautils.data_process(X_val, curr_vocab, tokenizer)\n",
    "X_test = datautils.data_process(X_test, curr_vocab, tokenizer)\n",
    "\n",
    "# create dataset objects\n",
    "X_train = datautils.TextDataset(X_train, y_train, curr_vocab)\n",
    "X_val = datautils.TextDataset(X_val, y_val, curr_vocab)\n",
    "X_test = datautils.TextDataset(X_test, y_test, curr_vocab)\n",
    "\n",
    "# save datasets\n",
    "torch.save(X_train, f\"{DATA_DIR}train_dataset.pt\")\n",
    "torch.save(X_val, f\"{DATA_DIR}val_dataset.pt\")\n",
    "torch.save(X_test, f\"{DATA_DIR}test_dataset.pt\")\n",
    "\n",
    "# save vocabulary with pickle\n",
    "with open(f\"{EMBED_DIR}vocab.pkl\", \"wb\") as f:\n",
    "    pickle.dump(curr_vocab, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training hold-out validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import itertools "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the datasets\n",
    "train_dataset = torch.load(f\"{DATA_DIR}train_dataset.pt\")\n",
    "val_dataset = torch.load(f\"{DATA_DIR}val_dataset.pt\")\n",
    "\n",
    "# load the vocabulary\n",
    "with open(f\"{EMBED_DIR}vocab.pkl\", \"rb\") as f:\n",
    "    curr_vocab = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 1000\n",
    "CLIP = 1\n",
    "BATCH_SIZE = 8\n",
    "EMBEDDING_DIM = 128\n",
    "HIDDEN_DIM = 1024\n",
    "OUTPUT_DIM = 1\n",
    "INPUT_DIM = len(curr_vocab)\n",
    "PATIECE = 10\n",
    "CHECKPOINT_STEPS = 10\n",
    "DROP_OUT = 0.2\n",
    "LAYERS = 3\n",
    "MEAN_POOL = True\n",
    "# experiment number\n",
    "RES_NUM = 12\n",
    "\n",
    "learning_rate_list = [0.001]\n",
    "weight_decay_list = [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNNutils.BiLSTM(\n",
    "    INPUT_DIM,\n",
    "    EMBEDDING_DIM,\n",
    "    HIDDEN_DIM,\n",
    "    output_dim=OUTPUT_DIM,\n",
    "    dropout=DROP_OUT,\n",
    "    n_layers=LAYERS,\n",
    "    mean_pooling=MEAN_POOL,\n",
    "    pretrained_embedding=None,\n",
    "    device=DEVICE, \n",
    ").to(DEVICE)\n",
    "\n",
    "train_iterator = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    collate_fn=train_dataset.generate_batch,\n",
    ")\n",
    "val_iterator = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    collate_fn=val_dataset.generate_batch,\n",
    ")\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BiLSTM(\n",
       "  (embedding): Embedding(9944, 128)\n",
       "  (lstm): LSTM(128, 1024, batch_first=True, bidirectional=True)\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "    (1): Dropout(p=0.2, inplace=False)\n",
       "    (2): Sigmoid()\n",
       "    (3): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (4): Dropout(p=0.2, inplace=False)\n",
       "    (5): Sigmoid()\n",
       "    (6): Linear(in_features=1024, out_features=1, bias=True)\n",
       "  )\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (activation): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mirda\\AppData\\Local\\Temp\\ipykernel_29984\\762118365.py:46: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results = pd.concat(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Time: 124.27s\n",
      "\tTrain Loss: 0.699\n",
      "\t Val. Loss: 0.707\n",
      "\t Val. Precision: 0.564, Recall: 0.553, F1 Score: 0.512\n",
      "Training...\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mirda\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 | Time: 114.05s\n",
      "\tTrain Loss: 0.701\n",
      "\t Val. Loss: 0.679\n",
      "\t Val. Precision: 0.284, Recall: 0.500, F1 Score: 0.362\n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 3 | Time: 129.25s\n",
      "\tTrain Loss: 0.697\n",
      "\t Val. Loss: 0.683\n",
      "\t Val. Precision: 0.564, Recall: 0.553, F1 Score: 0.512\n",
      "Training...\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mirda\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 | Time: 116.27s\n",
      "\tTrain Loss: 0.701\n",
      "\t Val. Loss: 0.679\n",
      "\t Val. Precision: 0.284, Recall: 0.500, F1 Score: 0.362\n",
      "Training...\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mirda\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 | Time: 133.80s\n",
      "\tTrain Loss: 0.697\n",
      "\t Val. Loss: 0.682\n",
      "\t Val. Precision: 0.284, Recall: 0.500, F1 Score: 0.362\n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 6 | Time: 124.27s\n",
      "\tTrain Loss: 0.697\n",
      "\t Val. Loss: 0.710\n",
      "\t Val. Precision: 0.564, Recall: 0.553, F1 Score: 0.512\n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 7 | Time: 125.58s\n",
      "\tTrain Loss: 0.698\n",
      "\t Val. Loss: 0.686\n",
      "\t Val. Precision: 0.564, Recall: 0.553, F1 Score: 0.512\n",
      "Training...\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mirda\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 | Time: 122.09s\n",
      "\tTrain Loss: 0.698\n",
      "\t Val. Loss: 0.688\n",
      "\t Val. Precision: 0.284, Recall: 0.500, F1 Score: 0.362\n",
      "Training...\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mirda\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 | Time: 139.52s\n",
      "\tTrain Loss: 0.697\n",
      "\t Val. Loss: 0.680\n",
      "\t Val. Precision: 0.284, Recall: 0.500, F1 Score: 0.362\n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 10 | Time: 177.75s\n",
      "\tTrain Loss: 0.698\n",
      "\t Val. Loss: 0.683\n",
      "\t Val. Precision: 0.564, Recall: 0.553, F1 Score: 0.512\n",
      "Training...\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mirda\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11 | Time: 203.36s\n",
      "\tTrain Loss: 0.697\n",
      "\t Val. Loss: 0.724\n",
      "\t Val. Precision: 0.284, Recall: 0.500, F1 Score: 0.362\n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 12 | Time: 191.53s\n",
      "\tTrain Loss: 0.703\n",
      "\t Val. Loss: 0.764\n",
      "\t Val. Precision: 0.216, Recall: 0.500, F1 Score: 0.302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mirda\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "min_loss = float(\"inf\")\n",
    "patience = PATIECE\n",
    "\n",
    "# initailize dataframe for results\n",
    "results = pd.DataFrame(\n",
    "    columns=[\n",
    "        \"optim\",\n",
    "        \"lr\",\n",
    "        \"weight_decay\",\n",
    "        \"epoch\",\n",
    "        \"train_loss\",\n",
    "        \"val_loss\",\n",
    "        \"precision\",\n",
    "        \"recall\",\n",
    "        \"f1_score\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "for lr, weight_decay in itertools.product(\n",
    "    learning_rate_list, weight_decay_list\n",
    "):\n",
    "\n",
    "    for epoch in range(N_EPOCHS):\n",
    "\n",
    "        start_time = time.process_time()\n",
    "\n",
    "        print(\"Training...\")\n",
    "        train_loss = RNNutils.train_rnn(\n",
    "            model,\n",
    "            train_iterator,\n",
    "            optimizer,\n",
    "            criterion,\n",
    "            CLIP,  # device=DEVICE\n",
    "            device=DEVICE,\n",
    "        )\n",
    "        print(\"Evaluating...\")\n",
    "        valid_loss, precision, recall, f1_score = RNNutils.evaluate(\n",
    "            model,\n",
    "            val_iterator,\n",
    "            criterion,  # device=DEVICE\n",
    "            device=DEVICE,\n",
    "        )\n",
    "\n",
    "        end_time = time.process_time()\n",
    "\n",
    "        results = pd.concat(\n",
    "            [\n",
    "                results,\n",
    "                pd.DataFrame(\n",
    "                    {\n",
    "                        \"optim\": \"Adam\",\n",
    "                        \"lr\": lr,\n",
    "                        \"weight_decay\": 0,\n",
    "                        \"epoch\": [epoch + 1],\n",
    "                        \"train_loss\": [train_loss],\n",
    "                        \"val_loss\": [valid_loss],\n",
    "                        \"precision\": [precision],\n",
    "                        \"recall\": [recall],\n",
    "                        \"f1_score\": [f1_score],\n",
    "                    }\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # save model checkpoint every 10 epochs\n",
    "        if (epoch + 1) % CHECKPOINT_STEPS == 0:\n",
    "            torch.save(\n",
    "                {\n",
    "                    \"epoch\": epoch,\n",
    "                    \"model_state_dict\": model.state_dict(),\n",
    "                    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "                    \"loss\": valid_loss,\n",
    "                    \"patience\": patience,\n",
    "                },\n",
    "                f\"{RES_DIR}rnn_checkpoint_{epoch + 1}.pt\",\n",
    "            )\n",
    "            results.to_csv(\n",
    "                f\"{RES_DIR}rnn_results-{RES_NUM}-temp.csv\", index=False\n",
    "            )\n",
    "\n",
    "        print(f\"Epoch: {epoch+1} | Time: {end_time-start_time:.2f}s\")\n",
    "        print(f\"\\tTrain Loss: {train_loss:.3f}\")\n",
    "        print(f\"\\t Val. Loss: {valid_loss:.3f}\")\n",
    "        print(\n",
    "            f\"\\t Val. Precision: {precision:.3f}, Recall: {recall:.3f}, F1 Score: {f1_score:.3f}\"\n",
    "        )\n",
    "\n",
    "        # early stopping\n",
    "        if valid_loss < min_loss:\n",
    "            min_loss = valid_loss\n",
    "            patience = PATIECE\n",
    "        else:\n",
    "            patience -= 1\n",
    "\n",
    "        if patience == 0:\n",
    "            break\n",
    "\n",
    "results.to_csv(f\"{RES_DIR}bilstm-results{RES_NUM}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_csv(f\"{RES_DIR}rnn_results-{RES_NUM}.csv\")\n",
    "results.sort_values(\"f1_score\", inplace=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 9\u001b[0m\n\u001b[0;32m      2\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mDATA_DIR\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mtest_dataset.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m test_iterator \u001b[38;5;241m=\u001b[39m DataLoader(\n\u001b[0;32m      4\u001b[0m     test_dataset,\n\u001b[0;32m      5\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE,\n\u001b[0;32m      6\u001b[0m     collate_fn\u001b[38;5;241m=\u001b[39mtrain_dataset\u001b[38;5;241m.\u001b[39mgenerate_batch,\n\u001b[0;32m      7\u001b[0m     shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,   \n\u001b[0;32m      8\u001b[0m )   \n\u001b[1;32m----> 9\u001b[0m test_loss, precision, recall, f1_score \u001b[38;5;241m=\u001b[39m \u001b[43mRNNutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_iterator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# device=DEVICE\u001b[39;49;00m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDEVICE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(test_loss, precision, recall, f1_score)\n",
      "File \u001b[1;32mc:\\UNI\\HLT\\NLP-project\\RNNutils.py:414\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(model, iterator, criterion, device)\u001b[0m\n\u001b[0;32m    411\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, (src, trg, src_len) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(iterator):\n\u001b[0;32m    412\u001b[0m     src, trg \u001b[38;5;241m=\u001b[39m src\u001b[38;5;241m.\u001b[39mto(device), trg\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m--> 414\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_len\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    415\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(output, trg\u001b[38;5;241m.\u001b[39mfloat())\n\u001b[0;32m    417\u001b[0m     epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\UNI\\HLT\\NLP-project\\RNNutils.py:330\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(self, x, x_lens)\u001b[0m\n\u001b[0;32m    323\u001b[0m         epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m    325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m epoch_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(iterator)\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate\u001b[39m(\n\u001b[1;32m--> 330\u001b[0m     model: nn\u001b[38;5;241m.\u001b[39mModule,\n\u001b[0;32m    331\u001b[0m     iterator: torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader,\n\u001b[0;32m    332\u001b[0m     criterion: nn\u001b[38;5;241m.\u001b[39mModule,\n\u001b[0;32m    333\u001b[0m     device: torch\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    334\u001b[0m ):\n\u001b[0;32m    335\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    336\u001b[0m \u001b[38;5;124;03m    Evaluate the model on the given data iterator.\u001b[39;00m\n\u001b[0;32m    337\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;124;03m        float: The average loss over the evaluation data.\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    347\u001b[0m     model\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\utils\\rnn.py:338\u001b[0m, in \u001b[0;36mpad_packed_sequence\u001b[1;34m(sequence, batch_first, padding_value, total_length)\u001b[0m\n\u001b[0;32m    336\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m unsorted_indices \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    337\u001b[0m     batch_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m batch_first \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 338\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m padded_output\u001b[38;5;241m.\u001b[39mindex_select(batch_dim, unsorted_indices), lengths[\u001b[43munsorted_indices\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[0;32m    339\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m padded_output, lengths\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "with torch.no_grad():\n",
    "    test_dataset = torch.load(f\"{DATA_DIR}test_dataset.pt\")\n",
    "    test_iterator = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        collate_fn=train_dataset.generate_batch,\n",
    "        shuffle=True,   \n",
    "    )   \n",
    "    test_loss, precision, recall, f1_score = RNNutils.evaluate(\n",
    "        model,\n",
    "        test_iterator,\n",
    "        criterion,  # device=DEVICE\n",
    "        device=DEVICE,\n",
    "    )\n",
    "    print(test_loss, precision, recall, f1_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HLT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
