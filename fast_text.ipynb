{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fast Text Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import fasttext\n",
    "from datautils import documents_vector\n",
    "import datautils\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "import pandas as pd\n",
    "PATH = './Dataset/power-gb-train.tsv'\n",
    "RES_DIR = './Results/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this cell below we apply two grid search: one for the hyperparameters of the fast text model in particular context window and vector size, the other one over the hyperparameters of the logistic regression. Here we are loking for the best combinations of these hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#here we split the dataset into training and validation\n",
    "X_train, y_train, X_val, y_val, _, _ = datautils.split_holdout_dataset(PATH)\n",
    "\n",
    "tr_fold = list(map(simple_preprocess, X_train))\n",
    "val_fold = list(map(simple_preprocess, X_val))\n",
    "\n",
    "#creation of the grid search over the context window and vector size\n",
    "hyperparameters = {\n",
    "        \"vector_size\": [150, 300,600],\n",
    "        \"window\": [10, 20, 30,40,50],\n",
    "}\n",
    "\n",
    "param_grid = list(ParameterGrid(hyperparameters))\n",
    "\n",
    "\n",
    "for par in param_grid:\n",
    "    # we create the fast text model\n",
    "    model_ftx = fasttext.FastText(\n",
    "            sentences=tr_fold,\n",
    "            vector_size=par['vector_size'],\n",
    "            window=par['window'],\n",
    "            min_count=2,\n",
    "            workers=10,\n",
    "        )\n",
    "\n",
    "    # Save word vectors\n",
    "    word_vectors = model_ftx.wv\n",
    "    word_vectors.save(f\"./Embeddings/ftx-w{par['window']}-s{par['vector_size']}.kv\")\n",
    "\n",
    "    # Pooling\n",
    "    X_train = documents_vector(tr_fold, model_ftx)\n",
    "    X_val = documents_vector(val_fold, model_ftx)\n",
    "\n",
    "    #definition of the hyper parameter of the logistic regression\n",
    "    hyperparameters1 = {\n",
    "            \"penalty\": [\"l2\"],\n",
    "            \"C\": [0.1, 1.0, 10.0, 100.0, 1000.0,1500],\n",
    "            \"solver\": [\"lbfgs\"],\n",
    "            \"max_iter\": [100, 200, 500,700],\n",
    "    }\n",
    "\n",
    "    param_grid1 = list(ParameterGrid(hyperparameters1))\n",
    "\n",
    "    #creation of dataframe where we are going to save the data\n",
    "    results_df = pd.DataFrame(\n",
    "        columns=[\"penalty\", \"C\", \"solver\", \"max_iter\",\"Precision\",\"Recall\" \"F1 Score\",\"Vector_size\",\"Window\"]\n",
    "    )\n",
    "\n",
    "    for par1 in param_grid1:\n",
    "            #cration o the logistic regression model with the htperparameters\n",
    "            #selected by the logistic regression\n",
    "            model = LogisticRegression(**par1)\n",
    "            #training of the logistic regression model\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            # Compute F1 score on validation set\n",
    "            y_val_pred = model.predict(X_val)\n",
    "            f1_macro = f1_score(y_val, y_val_pred, average=\"macro\")\n",
    "            recall= recall_score(y_val, y_val_pred)\n",
    "            precision=precision_score(y_val, y_val_pred)\n",
    "\n",
    "            print(f\"Parameters: {par1}\")\n",
    "            print(f\"\\tF1 score: {f1_macro}\")\n",
    "            #we save the combination of hyperparameters of the model and \n",
    "            # his scores\n",
    "            results_df = pd.concat(\n",
    "                [\n",
    "                    results_df,\n",
    "                    pd.DataFrame(\n",
    "                        {\n",
    "                            \"penalty\": par1[\"penalty\"],\n",
    "                            \"C\": par1[\"C\"],\n",
    "                            \"solver\": par1[\"solver\"],\n",
    "                            \"max_iter\": par1[\"max_iter\"],\n",
    "                            \"Precision\" : precision,\n",
    "                            \"Recall\": recall,\n",
    "                            \"F1 Score\": f1_macro,\n",
    "                            'Vector_size': par['vector_size'],\n",
    "                            'Window': par['window'],\n",
    "                        },\n",
    "                        index=[0],\n",
    "                    ),\n",
    "                ],\n",
    "                ignore_index=True,\n",
    "            )\n",
    "\n",
    "    results_df.to_csv(RES_DIR+f\"results-Logistic-ftx-w{par['window']}-s{par['vector_size']}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best combination of the hyperparameters of the logistic regression and vector size and context window, and tested over the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here we split the dataset into training, validation and test set\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = datautils.split_holdout_dataset(PATH)\n",
    "\n",
    "tr_fold = list(map(simple_preprocess, X_train))\n",
    "val_fold = list(map(simple_preprocess, X_val))\n",
    "test_fold = list(map(simple_preprocess, X_test))\n",
    "\n",
    "#using the values of the best values of context window and vector size\n",
    "model_ftx = fasttext.FastText(\n",
    "            sentences=tr_fold,\n",
    "            vector_size=600,\n",
    "            window=50,\n",
    "            min_count=2,\n",
    "            workers=10,\n",
    "        )\n",
    "\n",
    "# Save word vectors\n",
    "word_vectors = model_ftx.wv\n",
    "word_vectors.save(f\"./Embeddings/ftx-w{par['window']}-s{par['vector_size']}.kv\")\n",
    "\n",
    "# Pooling\n",
    "X_train = documents_vector(tr_fold, model_ftx)\n",
    "X_val = documents_vector(val_fold, model_ftx)\n",
    "X_test = documents_vector(test_fold, model_ftx)\n",
    "\n",
    "\n",
    "#using the best combination of hyperparameters for the logistic regression\n",
    "model = LogisticRegression(solver='lbfgs',penalty='l2',C=10,max_iter=500)\n",
    "#training of the logistic regression model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Compute F1 score,Recall precision on test set,\n",
    "y_test_pred = model.predict(X_test)\n",
    "f1_macro = f1_score(y_test, y_test_pred, average=\"macro\")\n",
    "recall= recall_score(y_test, y_test_pred)\n",
    "precision=precision_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"\\tF1 score: {f1_macro}\")\n",
    "print(f\"\\tRecall: {recall}\")\n",
    "print(f\"\\tPrecision: {precision}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this cell we download a test file for the word analogy in order to evaluate our best FastText model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = datautils.split_holdout_dataset(PATH)\n",
    "\n",
    "tr_fold = list(map(simple_preprocess, X_train))\n",
    "val_fold = list(map(simple_preprocess, X_val))\n",
    "test_fold = list(map(simple_preprocess, X_test))\n",
    "\n",
    "#using the values of the best values of context window and vector size\n",
    "model_ftx = fasttext.FastText(\n",
    "            sentences=tr_fold,\n",
    "            vector_size=600,\n",
    "            window=50,\n",
    "            min_count=2,\n",
    "            workers=10,\n",
    "        )\n",
    "\n",
    "X_train = documents_vector(tr_fold, model_ftx)\n",
    "X_val = documents_vector(val_fold, model_ftx)\n",
    "\n",
    "\n",
    "#we load the test file for the word analogy\n",
    "#this is the url of test file\n",
    "url = \"https://raw.githubusercontent.com/nicholas-leonard/word2vec/master/questions-words.txt\"\n",
    "test_file = 'resources/questions-words.txt'\n",
    "questions = requests.get(url).content.decode()\n",
    "with open(test_file,mode='w',encoding='utf-8') as outputfile:\n",
    "    outputfile.write(questions)\n",
    "print(questions[:1000])\n",
    "\n",
    "#we compute the word analogy without dummy4unknown\n",
    "ftx_large_analogy = model_ftx.evaluate_word_analogies(test_file)\n",
    "#we compute the word analogy with dummy4unknown\n",
    "ftx_large_analogy_dummy = model_ftx.evaluate_word_analogies(test_file,dummy4unknown=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we check teh scorre of the word analogy \n",
    "ftx_large_analogy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we check the score of the word analogy with dummy4unknown \n",
    "ftx_large_analogy_dummy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
